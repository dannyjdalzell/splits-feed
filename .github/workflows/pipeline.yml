name: pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: "*/15 * * * *"   # every 15 minutes

jobs:
  pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas

      - name: OCR splits (images → staged)
        run: |
          mkdir -p audit_out
          python scripts/splits_ocr.py \
            --images images \
            --out audit_out/splits_staged.csv

      - name: Twitter text analysis (signals)
        run: |
          mkdir -p audit_out
          python scripts/analyze_twitter_text.py \
            --csv sources/sheets/twitter/tweets.csv \
            --dict dictionaries \
            --out audit_out/twitter_text_signals.csv

      - name: Normalize + merge sources
        run: |
          mkdir -p audit_out
          python scripts/normalize_and_merge.py \
            --splits audit_out/splits_staged.csv \
            --twitter audit_out/twitter_text_signals.csv \
            --out audit_out/boardroom_inputs.csv

      - name: Promote staged → splits.csv (with fallback to boardroom_inputs)
        run: |
          python - <<'PY'
          import os, sys, pandas as pd

          ROOT = os.getcwd()
          AOUT = os.path.join(ROOT,"audit_out")
          staged = os.path.join(AOUT,"splits_staged.csv")
          board = os.path.join(AOUT,"boardroom_inputs.csv")
          OUT   = os.path.join(ROOT,"splits.csv")

          def exists_nonempty(p): return os.path.exists(p) and os.path.getsize(p)>0

          def promote_from_df(df):
              need={"away_team","home_team"}
              if not need.issubset(df.columns): return None
              df = df[(df["away_team"].str.len()>1)&(df["home_team"].str.len()>1)]
              if df.empty: return None
              return df[["timestamp","league","away_team","home_team","market","tickets_pct","handle_pct","line","source"]]

          if exists_nonempty(staged):
              df=pd.read_csv(staged,dtype=str).fillna("")
              out=promote_from_df(df)
              if out is not None:
                  out.to_csv(OUT,index=False); print("PROMOTE_OK (staged) rows:",len(out)); sys.exit(0)
              print("staged present but no valid rows; falling back")

          if exists_nonempty(board):
              df=pd.read_csv(board,dtype=str).fillna("")
              if {"team_a","team_b"}.issubset(df.columns):
                  df=df.rename(columns={"team_a":"away_team","team_b":"home_team"})
              out=promote_from_df(df)
              if out is not None:
                  out.to_csv(OUT,index=False); print("PROMOTE_OK (fallback) rows:",len(out)); sys.exit(0)

          print("nothing promotable (no valid rows)")
          PY

      - name: Live delta analysis (rolling; stop 15m pre-start)
        run: |
          python scripts/live_delta_analysis.py

      - name: Commit outputs
        run: |
          git config user.name  "splits-bot"
          git config user.email "actions@users.noreply.github.com"
          git add sources/sheets/twitter/tweets.csv || true
          git add audit_out/twitter_text_signals.csv audit_out/boardroom_inputs.csv || true
          git add splits.csv reports || true
          git commit -m "ci: refresh + promote + live-delta (auto)" || echo "no changes"
          git push
